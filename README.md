# nuScenes Multimodal Search ğŸš—ğŸ”

AI-Powered Multimodal Search System for Autonomous Driving Scenes using nuScenes Dataset

## ğŸŒŸ Features

- **Text-to-Scene Search**: Find driving scenes using natural language queries (e.g., "rainy intersection")
- **Image-to-Scene Search**: Upload an image to find visually similar driving scenarios
- **UMAP Visualization**: Interactive 2D visualization of scene embeddings
- **AI-Powered**: Uses MINI CLIP model with MobileNetV3 and multilingual BERT
- **AWS Serverless**: Deployed on AWS Lambda, API Gateway, S3, and CloudFront
- **ONNX Optimized**: Fast inference with ONNX Runtime
- **Low Cost**: Serverless architecture with estimated $5-10/month cost

## ğŸ—ï¸ Architecture

### Backend (AWS Lambda + FastAPI)
- **Text Encoder**: `sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2` (ONNX)
- **Image Encoder**: MobileNetV3-Small with custom projection head (ONNX)
- **Embedding Dimension**: 256
- **Vector Database**: S3-based JSON vector store (with S3 Vectors migration path)
- **Runtime**: AWS Lambda with Docker container
- **API**: API Gateway HTTP API

### Frontend (Next.js 15 + CloudFront)
- **Framework**: Next.js 15 with React 19
- **Styling**: Tailwind CSS 4
- **Deployment**: Static export to S3 + CloudFront CDN
- **Visualization**: Plotly.js for UMAP scatter plots

### Infrastructure (AWS CDK)
- **IaC**: AWS CDK (TypeScript)
- **Compute**: Lambda (512MB, 30s timeout)
- **Storage**: S3 (models, data, images, frontend)
- **CDN**: CloudFront
- **Monitoring**: CloudWatch Logs (7-day retention)

## ğŸ“ Project Structure

```
.
â”œâ”€â”€ lambda/                      # AWS Lambda function
â”‚   â”œâ”€â”€ lambda_function.py       # Lambda handler
â”‚   â”œâ”€â”€ encoders.py              # PyTorch encoders
â”‚   â”œâ”€â”€ encoders_onnx.py         # ONNX encoders (optimized)
â”‚   â”œâ”€â”€ vector_db.py             # Vector database
â”‚   â”œâ”€â”€ vector_db_s3vectors.py   # S3 Vectors integration
â”‚   â”œâ”€â”€ Dockerfile               # Lambda container
â”‚   â”œâ”€â”€ requirements.txt
â”‚   â””â”€â”€ models/                  # ONNX models (generated)
â”‚       â”œâ”€â”€ text_transformer.onnx
â”‚       â”œâ”€â”€ text_projector.onnx
â”‚       â”œâ”€â”€ image_features.onnx
â”‚       â””â”€â”€ image_projector.onnx
â”œâ”€â”€ infrastructure/cdk/          # AWS CDK infrastructure
â”‚   â”œâ”€â”€ lib/
â”‚   â”‚   â””â”€â”€ nuscenes-search-stack.ts
â”‚   â”œâ”€â”€ bin/
â”‚   â”‚   â””â”€â”€ app.ts
â”‚   â””â”€â”€ package.json
â”œâ”€â”€ integ-app/                   # Local development
â”‚   â”œâ”€â”€ backend/                 # FastAPI backend
â”‚   â”‚   â””â”€â”€ app/
â”‚   â”‚       â”œâ”€â”€ encoders.py
â”‚   â”‚       â”œâ”€â”€ main.py
â”‚   â”‚       â””â”€â”€ model/           # PyTorch models & data
â”‚   â””â”€â”€ frontend/                # Next.js frontend
â”‚       â”œâ”€â”€ src/
â”‚       â”‚   â”œâ”€â”€ app/
â”‚       â”‚   â”œâ”€â”€ components/
â”‚       â”‚   â””â”€â”€ lib/
â”‚       â””â”€â”€ package.json
â”œâ”€â”€ data_preparation/            # Data processing scripts
â”‚   â”œâ”€â”€ extract_nuscenes.py
â”‚   â”œâ”€â”€ generate_embeddings.py
â”‚   â”œâ”€â”€ generate_umap.py
â”‚   â”œâ”€â”€ convert_to_onnx.py       # PyTorch â†’ ONNX conversion
â”‚   â”œâ”€â”€ upload_to_s3.py
â”‚   â””â”€â”€ extracted_data/
â”‚       â””â”€â”€ images/              # Scene images
â”œâ”€â”€ deploy.sh                    # Deployment script (Linux/Mac)
â”œâ”€â”€ deploy.ps1                   # Deployment script (Windows)
â””â”€â”€ DEPLOYMENT_INSTRUCTIONS.md   # Detailed deployment guide
```

## ğŸš€ Getting Started

### Prerequisites

- **AWS Account** with configured credentials
- **AWS CLI** installed and configured
- **AWS CDK** installed (`npm install -g aws-cdk`)
- **Node.js 18+**
- **Python 3.11+** with `uv/uvx`
- **Docker** (for Lambda container builds)

### Quick Start (Local Development)

1. **Clone the repository**
   ```bash
   git clone <your-repo-url>
   cd sampleClip
   ```

2. **Start local development environment**
   ```bash
   cd integ-app
   docker-compose up --build
   ```

3. **Access the application**
   - Frontend: http://localhost:3000
   - Backend API: http://localhost:8000
   - API Documentation: http://localhost:8000/docs

### AWS Deployment

See [DEPLOYMENT_INSTRUCTIONS.md](DEPLOYMENT_INSTRUCTIONS.md) for detailed deployment guide.

**Quick Deploy:**
```bash
# Linux/Mac
./deploy.sh

# Windows
.\deploy.ps1
```

This will:
1. Convert PyTorch models to ONNX
2. Deploy CDK infrastructure
3. Build and deploy frontend
4. Configure CloudFront CDN

## ğŸ”§ Configuration

### Environment Variables

#### Backend (`docker-compose.yml`)
```yaml
environment:
  - MODEL_DIR=/app/app/model
```

#### Frontend (`docker-compose.yml`)
```yaml
environment:
  - NEXT_PUBLIC_API_URL=http://localhost:8000
  - NODE_ENV=development
  - WATCHPACK_POLLING=true
```

### GPU Support

The application is configured to use NVIDIA GPUs if available. To disable GPU:

Remove the following from `docker-compose.yml`:
```yaml
deploy:
  resources:
    reservations:
      devices:
        - driver: nvidia
          count: 1
          capabilities: [gpu]
```

## ğŸ“¡ API Endpoints

### POST `/predict/text`
Search for images using text query

**Request:**
- `query` (form-data): Search text
- `top_k` (form-data): Number of results (default: 5)

**Response:**
```json
{
  "query": "funny cat",
  "results": [
    {
      "image_url": "/static/memes/memes/memes/memes_xxx.png",
      "caption": "Meme description",
      "similarity": 0.8542
    }
  ]
}
```

### POST `/predict/image`
Search for similar images using an uploaded image

**Request:**
- `file` (form-data): Image file
- `top_k` (form-data): Number of results (default: 5)

**Response:**
```json
{
  "results": [
    {
      "image_url": "/static/memes/memes/memes/memes_xxx.png",
      "caption": "Meme description",
      "similarity": 0.9123
    }
  ]
}
```

## ğŸ¨ UI Features

- **Dual Search Modes**: Toggle between text and image search
- **Drag & Drop**: Upload images by clicking or dragging
- **Responsive Grid**: Adapts to different screen sizes
- **Similarity Scores**: Visual badges showing match percentage
- **Gradient Design**: Modern gradient-based color scheme
- **Smooth Animations**: Hover effects and transitions
- **Empty States**: Helpful prompts when no results

## ğŸ› ï¸ Development

### Backend Development
```bash
cd backend
pip install -r requirements.txt
uvicorn app.main:app --reload
```

### Frontend Development
```bash
cd frontend
npm install
npm run dev
```

## ğŸ“Š Model Details

### Text Encoder
- Base Model: `paraphrase-multilingual-MiniLM-L12-v2`
- Hidden Size: 384
- Projection: Linear(384 â†’ 256)
- Normalization: L2 normalized embeddings
- Format: ONNX (optimized for Lambda)

### Image Encoder
- Base Model: MobileNetV3-Small
- Feature Dimension: 576
- Projection: Linear(576 â†’ 256)
- Normalization: L2 normalized embeddings
- Input Size: 224Ã—224
- Format: ONNX (optimized for Lambda)

### Dataset
- Source: nuScenes Mini (10 scenes)
- Images: Front camera views (512Ã—512)
- Metadata: Scene descriptions, locations, timestamps
- UMAP: 2D coordinates for visualization

### Training
- Loss: CLIP-style contrastive loss
- Optimizer: AdamW
- Dataset: nuScenes with scene descriptions

## ğŸ” Vector Search

The application uses cosine similarity for vector search:

```python
similarity = dot(query_vec, item_vec) / (norm(query_vec) * norm(item_vec))
```

Results are sorted by similarity score (0-1, higher is better).

## ğŸ’° Cost Estimation

Monthly cost for AWS deployment (low traffic):

| Service | Cost |
|---------|------|
| Lambda | $0-5 (free tier) |
| API Gateway | $0-3 |
| S3 | $1-2 |
| CloudFront | $0-2 |
| ECR | $0-1 |
| **Total** | **$5-10/month** |

## ğŸ³ Local Development

### Build Images
```bash
cd integ-app
docker-compose build
```

### Start Services
```bash
docker-compose up -d
```

### Stop Services
```bash
docker-compose down
```

### View Logs
```bash
docker-compose logs -f
```

## ğŸ“ License

This project is for educational purposes.

## ğŸ—ºï¸ Roadmap

- [x] Basic text and image search
- [x] UMAP visualization
- [x] AWS serverless deployment
- [x] ONNX optimization
- [ ] S3 Vectors (GA) migration
- [ ] More nuScenes scenes (50-100)
- [ ] MCAP time-series data integration
- [ ] Custom domain with Route 53
- [ ] Authentication with Cognito
- [ ] Real-time monitoring dashboard

## ğŸ™ Acknowledgments

- [nuScenes Dataset](https://www.nuscenes.org/) by Motional
- CLIP paper by OpenAI
- Hugging Face Transformers
- PyTorch and ONNX Runtime teams
- AWS CDK team
- Next.js and React teams
- FastAPI team

## ğŸ“š Documentation

- [Deployment Instructions](DEPLOYMENT_INSTRUCTIONS.md)
- [S3 Vectors Migration Guide](S3_VECTORS_MIGRATION.md)
- [Security Best Practices](SECURITY_BEST_PRACTICES.md)
- [CDK Quick Start](infrastructure/cdk/QUICKSTART.md)

## ğŸ¤ Contributing

Contributions are welcome! Please feel free to submit a Pull Request.

## ğŸ“® Support

For issues and questions, please open an issue on GitHub.