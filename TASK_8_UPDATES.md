# タスク8の更新内容

## 変更の概要

タスク8「デプロイとデータアップロード」を、より実用的で自動化されたワークフローに改善しました。

## 主な変更点

### 1. 新規タスク 7.9: nuScenes大規模データ処理とローカル検証

**目的**: 本番デプロイ前に、より多くのデータでローカル環境での動作確認を行う

**サブタスク:**
- 7.9.1: nuScenes Miniデータセット全体（約10GB）のダウンロード
- 7.9.2: 50-100シーンの抽出（現在は10シーンのみ）
- 7.9.3: 大規模データの埋め込み生成
- 7.9.4: ローカルDocker環境での統合テスト

**メリット:**
- 本番環境にデプロイする前に、大規模データでの動作を確認できる
- パフォーマンスボトルネックを事前に発見できる
- より現実的なユースケースでテストできる

### 2. タスク8の再構成: CDK統合デプロイ

**旧構成（手動デプロイ）:**
- 8.1: ONNX変換（手動）
- 8.2: S3アップロード（手動）
- 8.3: Lambda パッケージング（手動）
- 8.4: CDKデプロイ
- 8.5: フロントエンドデプロイ（手動）

**新構成（自動化デプロイ）:**
- 8.1: Lambda Dockerイメージの準備
- 8.2: CDKスタックへのBucketDeployment追加
- 8.3: フロントエンドビルドのCDK統合
- 8.4: 統合デプロイスクリプトの作成
- 8.5: 本番環境へのデプロイ実行

**メリット:**
- ワンコマンドでデプロイ可能（`./deploy.sh`）
- CDK BucketDeploymentで自動的にS3にアップロード
- 手動ステップの削減によるヒューマンエラーの防止
- 再現性の高いデプロイプロセス

## 技術的な改善点

### 1. CDK BucketDeployment の活用

**旧方式:**
```bash
# 手動でS3にアップロード
aws s3 cp models/ s3://bucket/models/ --recursive
aws s3 cp data/ s3://bucket/data/ --recursive
```

**新方式:**
```typescript
// CDKスタックに統合
new s3deploy.BucketDeployment(this, 'DeployData', {
  sources: [s3deploy.Source.asset('../data_preparation/extracted_data')],
  destinationBucket: dataBucket,
  destinationKeyPrefix: 'data/',
});
```

**メリット:**
- デプロイ時に自動的にアップロード
- 変更されたファイルのみアップロード（差分デプロイ）
- CloudFormationで管理されるため、削除時も自動クリーンアップ

### 2. Lambda Dockerイメージの使用

**旧方式:**
- Lambda Layer + デプロイパッケージ
- ONNX変換が必要
- サイズ制限が厳しい（250MB）

**新方式:**
- Lambda Dockerイメージ
- PyTorchモデルをそのまま使用可能
- サイズ制限が緩い（10GB）

**メリット:**
- ONNX変換が不要（PyTorchモデルをそのまま使用）
- より大きなモデルを使用可能
- ローカル環境と同じDockerイメージを使用

### 3. 統合デプロイスクリプト

**deploy.sh / deploy.ps1:**
```bash
#!/bin/bash
# 1. 前提条件チェック
# 2. フロントエンドビルド
# 3. Lambda Dockerイメージビルド
# 4. CDKデプロイ
```

**メリット:**
- ワンコマンドでデプロイ完了
- エラーハンドリングの統一
- クロスプラットフォーム対応（Linux/Mac/Windows）

## ワークフローの比較

### 旧ワークフロー（手動）

```
1. PyTorchモデルをONNXに変換
2. AWS CLIでS3にアップロード
3. Lambda Layerを作成
4. デプロイパッケージを作成
5. CDKデプロイ
6. フロントエンドをビルド
7. S3にアップロード
8. CloudFrontキャッシュを無効化
```

**問題点:**
- 手順が多く、ミスが発生しやすい
- 各ステップを手動で実行する必要がある
- 再現性が低い

### 新ワークフロー（自動化）

```
1. ローカルで大規模データテスト（タスク 7.9）
2. ./deploy.sh を実行（タスク 8）
   → すべて自動で完了
```

**改善点:**
- 手順が大幅に削減
- ヒューマンエラーの防止
- 高い再現性

## 実装の優先順位

### フェーズ1: ローカル検証（タスク 7.9）
1. nuScenes Miniデータセットのダウンロード
2. 50-100シーンの処理
3. ローカルDocker環境でのテスト

### フェーズ2: CDK統合（タスク 8.1-8.4）
1. Lambda Dockerイメージの準備
2. CDKスタックの更新
3. デプロイスクリプトの作成

### フェーズ3: 本番デプロイ（タスク 8.5-8.6）
1. 本番環境へのデプロイ
2. 統合テスト

## 次のステップ

タスク 7.9 から開始することをお勧めします：

```bash
# タスク 7.9.1: nuScenes Miniデータセットのダウンロード
# 公式サイトからダウンロード: https://www.nuscenes.org/nuscenes#download
```

これにより、本番デプロイ前に大規模データでの動作を確認できます。

## 質問・サポート

- デプロイメントガイド: `DEPLOYMENT_GUIDE.md`
- CDK README: `infrastructure/cdk/README.md`
- Lambda README: `lambda/README.md`
