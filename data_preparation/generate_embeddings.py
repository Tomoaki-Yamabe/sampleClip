"""
åŸ‹ã‚è¾¼ã¿ãƒ™ã‚¯ãƒˆãƒ«ç”Ÿæˆã‚¹ã‚¯ãƒªãƒ—ãƒˆ

æ—¢å­˜ã®ãƒ†ã‚­ã‚¹ãƒˆã‚¨ãƒ³ã‚³ãƒ¼ãƒ€ãƒ¼ã¨ç”»åƒã‚¨ãƒ³ã‚³ãƒ¼ãƒ€ãƒ¼ã‚’ä½¿ç”¨ã—ã¦ã€
æŠ½å‡ºã•ã‚ŒãŸã‚·ãƒ¼ãƒ³ãƒ‡ãƒ¼ã‚¿ã®åŸ‹ã‚è¾¼ã¿ãƒ™ã‚¯ãƒˆãƒ«ã‚’ç”Ÿæˆã—ã¾ã™ã€‚

è¦ä»¶: 1.2
"""

import os
import sys
import json
import argparse
from pathlib import Path
import numpy as np

# æ—¢å­˜ã®ã‚¨ãƒ³ã‚³ãƒ¼ãƒ€ãƒ¼ã‚’ã‚¤ãƒ³ãƒãƒ¼ãƒˆ
sys.path.insert(0, str(Path(__file__).parent.parent / "integ-app" / "backend"))
from app.encoders import TextEncoder, ImageEncoder, DEVICE

import torch
from PIL import Image


def load_scenes_metadata(metadata_path: str) -> list:
    """
    ã‚·ãƒ¼ãƒ³ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿ã‚’ãƒ­ãƒ¼ãƒ‰
    
    Args:
        metadata_path: ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿JSONãƒ•ã‚¡ã‚¤ãƒ«ã®ãƒ‘ã‚¹
        
    Returns:
        ã‚·ãƒ¼ãƒ³ãƒ‡ãƒ¼ã‚¿ã®ãƒªã‚¹ãƒˆ
    """
    with open(metadata_path, 'r', encoding='utf-8') as f:
        scenes = json.load(f)
    return scenes


def generate_embeddings(
    metadata_path: str,
    text_projector_path: str,
    image_projector_path: str,
    output_path: str,
    batch_size: int = 8,
    save_interval: int = 10
):
    """
    ãƒ†ã‚­ã‚¹ãƒˆã¨ç”»åƒã®åŸ‹ã‚è¾¼ã¿ãƒ™ã‚¯ãƒˆãƒ«ã‚’ç”Ÿæˆï¼ˆãƒãƒƒãƒå‡¦ç†å¯¾å¿œï¼‰
    
    Args:
        metadata_path: ã‚·ãƒ¼ãƒ³ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿ã®ãƒ‘ã‚¹
        text_projector_path: ãƒ†ã‚­ã‚¹ãƒˆãƒ—ãƒ­ã‚¸ã‚§ã‚¯ã‚¿ãƒ¼ãƒ¢ãƒ‡ãƒ«ã®ãƒ‘ã‚¹
        image_projector_path: ç”»åƒãƒ—ãƒ­ã‚¸ã‚§ã‚¯ã‚¿ãƒ¼ãƒ¢ãƒ‡ãƒ«ã®ãƒ‘ã‚¹
        output_path: å‡ºåŠ›ãƒ•ã‚¡ã‚¤ãƒ«ã®ãƒ‘ã‚¹
        batch_size: ãƒãƒƒãƒã‚µã‚¤ã‚ºï¼ˆç”»åƒå‡¦ç†ç”¨ï¼‰
        save_interval: ä¸­é–“ä¿å­˜ã®é–“éš”ï¼ˆã‚·ãƒ¼ãƒ³æ•°ï¼‰
    """
    import time
    
    print("=" * 70)
    print("Embedding Generation")
    print("=" * 70)
    print(f"Device: {DEVICE}")
    print(f"Batch size: {batch_size}")
    print(f"Save interval: {save_interval} scenes")
    print("=" * 70)
    
    # ã‚¨ãƒ³ã‚³ãƒ¼ãƒ€ãƒ¼ã®åˆæœŸåŒ–
    print(f"\nLoading encoders...")
    start_time = time.time()
    
    text_encoder = TextEncoder(projector_path=text_projector_path, device=DEVICE)
    image_encoder = ImageEncoder(projector_path=image_projector_path, device=DEVICE)
    
    load_time = time.time() - start_time
    print(f"  âœ“ Text encoder loaded from: {text_projector_path}")
    print(f"  âœ“ Image encoder loaded from: {image_projector_path}")
    print(f"  âœ“ Load time: {load_time:.2f}s")
    
    # ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿ã‚’ãƒ­ãƒ¼ãƒ‰
    print(f"\nLoading scenes metadata from: {metadata_path}")
    scenes = load_scenes_metadata(metadata_path)
    print(f"  âœ“ Loaded {len(scenes)} scenes")
    
    # åŸ‹ã‚è¾¼ã¿ãƒ™ã‚¯ãƒˆãƒ«ã‚’ç”Ÿæˆ
    print(f"\nGenerating embeddings...")
    print("-" * 70)
    
    base_dir = Path(metadata_path).parent
    total_scenes = len(scenes)
    start_time = time.time()
    
    # é€²æ—è¿½è·¡
    processed_count = 0
    error_count = 0
    
    for i, scene in enumerate(scenes):
        scene_id = scene['scene_id']
        description = scene['description']
        image_rel_path = scene['image_path']
        image_path = base_dir / image_rel_path
        
        # é€²æ—è¡¨ç¤º
        progress_pct = (i + 1) / total_scenes * 100
        elapsed = time.time() - start_time
        avg_time = elapsed / (i + 1) if i > 0 else 0
        eta = avg_time * (total_scenes - i - 1)
        
        print(f"\n[{i+1}/{total_scenes}] {scene_id} ({progress_pct:.1f}%)")
        print(f"  ETA: {eta:.1f}s | Elapsed: {elapsed:.1f}s | Avg: {avg_time:.2f}s/scene")
        
        try:
            # ãƒ†ã‚­ã‚¹ãƒˆåŸ‹ã‚è¾¼ã¿
            text_embedding = text_encoder.encode(description, normalize=True)
            text_vec = text_embedding.cpu().detach().numpy()[0]
            
            # L2ãƒãƒ«ãƒ ã‚’ç¢ºèª
            text_norm = np.linalg.norm(text_vec)
            
            # ç”»åƒåŸ‹ã‚è¾¼ã¿
            if image_path.exists():
                image = Image.open(image_path).convert('RGB')
                image_embedding = image_encoder.encode(image, normalize=True)
                image_vec = image_embedding.cpu().detach().numpy()[0]
                
                # L2ãƒãƒ«ãƒ ã‚’ç¢ºèª
                image_norm = np.linalg.norm(image_vec)
                
                print(f"  âœ“ Text norm: {text_norm:.6f} | Image norm: {image_norm:.6f}")
            else:
                print(f"  âš  Image not found: {image_path}")
                # ãƒ€ãƒŸãƒ¼ã®æ­£è¦åŒ–ã•ã‚ŒãŸãƒ™ã‚¯ãƒˆãƒ«ã‚’ç”Ÿæˆ
                image_vec = np.random.randn(256).astype(np.float32)
                image_vec = image_vec / np.linalg.norm(image_vec)
                print(f"  âœ“ Text norm: {text_norm:.6f} | Image: dummy vector")
            
            # åŸ‹ã‚è¾¼ã¿ã‚’ã‚·ãƒ¼ãƒ³ãƒ‡ãƒ¼ã‚¿ã«è¿½åŠ 
            scene['text_embedding'] = text_vec.tolist()
            scene['image_embedding'] = image_vec.tolist()
            
            processed_count += 1
            
            # ä¸­é–“ä¿å­˜
            if (i + 1) % save_interval == 0:
                temp_output = Path(output_path).with_suffix('.tmp.json')
                with open(temp_output, 'w', encoding='utf-8') as f:
                    json.dump(scenes[:i+1], f, ensure_ascii=False, indent=2)
                print(f"  ğŸ’¾ Intermediate save: {i+1} scenes")
        
        except Exception as e:
            print(f"  âœ— Error processing {scene_id}: {e}")
            error_count += 1
            # ã‚¨ãƒ©ãƒ¼ã®å ´åˆã¯ãƒ€ãƒŸãƒ¼ãƒ™ã‚¯ãƒˆãƒ«ã‚’ä½¿ç”¨
            scene['text_embedding'] = (np.random.randn(384) / np.sqrt(384)).tolist()
            scene['image_embedding'] = (np.random.randn(256) / np.sqrt(256)).tolist()
            continue
    
    # æœ€çµ‚çµæœã‚’ä¿å­˜
    output_path = Path(output_path)
    output_path.parent.mkdir(parents=True, exist_ok=True)
    
    with open(output_path, 'w', encoding='utf-8') as f:
        json.dump(scenes, f, ensure_ascii=False, indent=2)
    
    # ä¸€æ™‚ãƒ•ã‚¡ã‚¤ãƒ«ã‚’å‰Šé™¤
    temp_output = output_path.with_suffix('.tmp.json')
    if temp_output.exists():
        temp_output.unlink()
    
    total_time = time.time() - start_time
    avg_time_per_scene = total_time / total_scenes
    
    print("\n" + "=" * 70)
    print("âœ… Embeddings generation complete!")
    print("=" * 70)
    print(f"Output: {output_path}")
    print(f"Total scenes: {total_scenes}")
    print(f"Processed: {processed_count}")
    print(f"Errors: {error_count}")
    print(f"Total time: {total_time:.2f}s")
    print(f"Average time: {avg_time_per_scene:.2f}s/scene")
    print("=" * 70)


def main():
    parser = argparse.ArgumentParser(
        description='Generate embeddings for extracted scenes',
        formatter_class=argparse.RawDescriptionHelpFormatter,
        epilog="""
Examples:
  # Generate embeddings for 10 scenes
  python generate_embeddings.py
  
  # Generate embeddings for 50 scenes with custom batch size
  python generate_embeddings.py --batch-size 16 --save-interval 5
  
  # Generate embeddings with custom paths
  python generate_embeddings.py --metadata extracted_data/scenes_metadata.json --output extracted_data/embeddings.json
        """
    )
    parser.add_argument(
        '--metadata',
        type=str,
        default='data_preparation/extracted_data/scenes_metadata.json',
        help='Path to scenes metadata JSON file'
    )
    parser.add_argument(
        '--text-projector',
        type=str,
        default='integ-app/backend/app/model/text_projector.pt',
        help='Path to text projector model'
    )
    parser.add_argument(
        '--image-projector',
        type=str,
        default='integ-app/backend/app/model/image_projector.pt',
        help='Path to image projector model'
    )
    parser.add_argument(
        '--output',
        type=str,
        default='data_preparation/extracted_data/scenes_with_embeddings.json',
        help='Output path for scenes with embeddings'
    )
    parser.add_argument(
        '--batch-size',
        type=int,
        default=8,
        help='Batch size for image processing (default: 8)'
    )
    parser.add_argument(
        '--save-interval',
        type=int,
        default=10,
        help='Save intermediate results every N scenes (default: 10)'
    )
    
    args = parser.parse_args()
    
    # Validate paths
    if not Path(args.metadata).exists():
        print(f"Error: Metadata file not found: {args.metadata}")
        print("Please run extract_nuscenes.py first to generate scene metadata")
        sys.exit(1)
    
    if not Path(args.text_projector).exists():
        print(f"Error: Text projector not found: {args.text_projector}")
        sys.exit(1)
    
    if not Path(args.image_projector).exists():
        print(f"Error: Image projector not found: {args.image_projector}")
        sys.exit(1)
    
    generate_embeddings(
        metadata_path=args.metadata,
        text_projector_path=args.text_projector,
        image_projector_path=args.image_projector,
        output_path=args.output,
        batch_size=args.batch_size,
        save_interval=args.save_interval
    )


if __name__ == "__main__":
    main()
